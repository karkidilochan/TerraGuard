{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "from api_keys import GEMINI_API_KEY\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"autoiac-project/iac-eval\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Resource', 'Prompt', 'Rego intent', 'Difficulty', 'Reference output',\n",
      "       'Intent'],\n",
      "      dtype='object')\n",
      "(458, 6)\n"
     ]
    }
   ],
   "source": [
    "df = dataset.to_pandas()\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      terraform {\\n  required_providers {\\n    aws =...\n",
       "1      provider \"aws\" {\\n    region = \"us-east-1\"\\n}\\...\n",
       "2      provider \"aws\" {\\n  region = \"us-east-1\"\\n}\\n\\...\n",
       "3      terraform {\\n  required_providers {\\n    aws =...\n",
       "4      terraform {\\n  required_providers {\\n    aws =...\n",
       "                             ...                        \n",
       "453    terraform {\\n  required_providers {\\n    aws =...\n",
       "454    terraform {\\n  required_providers {\\n    aws =...\n",
       "455    provider \"aws\" {\\n  region = \"us-west-1\"\\n}\\n\\...\n",
       "456    terraform {\\n  required_providers {\\n    aws =...\n",
       "457    terraform {\\n  required_providers {\\n    aws =...\n",
       "Name: Reference output, Length: 458, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Reference output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(\"templates/system_prompt.txt\", \"r\") as f:\n",
    "    system_prompt = f.read()\n",
    "\n",
    "with open(\"templates/cot.txt\", \"r\") as f:\n",
    "    cot_prompt = f.read()\n",
    "\n",
    "with open(\"templates/few-shot.txt\", \"r\") as f:\n",
    "    few_shot_prompt = f.read()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, I will create a Terraform configuration that sets up Route 53 query logging, including a CloudWatch Log Group, a Log Stream, and a Resource Policy to allow Route 53 to write logs to CloudWatch.\\n\\n```terraform\\n# Configure the AWS Provider\\nterraform {\\n  required_providers {\\n    aws = {\\n      source  = \"hashicorp/aws\"\\n      version = \"~> 5.0\"\\n    }\\n  }\\n}\\n\\nprovider \"aws\" {\\n  region = \"us-east-1\"\\n}\\n\\n# Define variables\\nvariable \"domain_name\" {\\n  type    = string\\n  default = \"example.com\"\\n  description = \"The domain name for the Route 53 zone.\"\\n}\\n\\nvariable \"zone_name\" {\\n  type    = string\\n  default = \"primary\"\\n  description = \"The name of the Route 53 zone.\"\\n}\\n\\nvariable \"log_group_name\" {\\n  type    = string\\n  default = \"aws_route53_example_com\"\\n  description = \"The name of the CloudWatch Log Group.\"\\n}\\n\\nvariable \"log_retention_days\" {\\n  type    = number\\n  default = 7\\n  description = \"Number of days to retain logs in CloudWatch.\"\\n}\\n\\nvariable \"policy_name\" {\\n  type    = string\\n  default = \"route53-query-logging-policy\"\\n  description = \"The name of the CloudWatch Resource Policy.\"\\n}\\n\\n# Create a Route 53 Zone\\nresource \"aws_route53_zone\" \"primary\" {\\n  name = var.domain_name\\n\\n  tags = {\\n    Name = \"${var.zone_name}-zone\"\\n  }\\n}\\n\\n# Create a CloudWatch Log Group\\nresource \"aws_cloudwatch_log_group\" \"route53_log_group\" {\\n  name              = var.log_group_name\\n  retention_in_days = var.log_retention_days\\n\\n  tags = {\\n    Name = var.log_group_name\\n  }\\n}\\n\\n# Create a CloudWatch Log Stream\\nresource \"aws_cloudwatch_log_stream\" \"route53_log_stream\" {'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = gemini_client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\", \n",
    "        config = types.GenerateContentConfig(\n",
    "            temperature=0.1,\n",
    "            top_p=0.9,\n",
    "            system_instruction=system_prompt,\n",
    "        ),\n",
    "        contents=df['Prompt'][0]\n",
    "    )\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down how AI works in a way that's understandable, even if you don't have a computer science background.  We'll cover the core concepts and some examples.\n",
      "\n",
      "**The Basic Idea: Mimicking Intelligence**\n",
      "\n",
      "At its heart, AI is about creating machines that can perform tasks that typically require human intelligence. This includes things like:\n",
      "\n",
      "*   **Learning:**  Improving performance over time based on data.\n",
      "*   **Reasoning:** Drawing conclusions and making decisions based on available information.\n",
      "*   **Problem-solving:** Finding solutions to complex issues.\n",
      "*   **Perception:** Understanding the world through senses (like sight, hearing, etc.).\n",
      "*   **Natural Language Processing:** Understanding and generating human language.\n",
      "\n",
      "**Key Components and Techniques**\n",
      "\n",
      "1.  **Data:**  AI algorithms are \"trained\" on vast amounts of data.  The more data, generally the better the AI performs. Think of it like a student learning from textbooks and examples.\n",
      "\n",
      "2.  **Algorithms:** These are sets of instructions that tell the computer how to process the data and perform a specific task. There are many different types of algorithms, each suited for different kinds of problems.\n",
      "\n",
      "3.  **Machine Learning (ML): The Engine of Many AI Systems**\n",
      "\n",
      "    *   Machine learning is a subfield of AI that focuses on enabling computers to learn from data *without being explicitly programmed*. Instead of writing specific rules for every situation, you give the machine a bunch of examples, and it figures out the rules itself.\n",
      "\n",
      "    *   **Types of Machine Learning:**\n",
      "\n",
      "        *   **Supervised Learning:**  You give the algorithm labeled data (inputs and the correct outputs). The algorithm learns to map inputs to outputs. Example:  You show the algorithm thousands of pictures of cats and dogs, labeled as \"cat\" or \"dog.\"  The algorithm learns to recognize the features that distinguish cats from dogs and can then classify new pictures.\n",
      "\n",
      "        *   **Unsupervised Learning:** You give the algorithm unlabeled data. The algorithm tries to find patterns, structures, and relationships in the data on its own. Example:  You give the algorithm a bunch of customer purchase data. The algorithm might identify different customer segments based on their buying habits (e.g., high-spending customers, bargain hunters, etc.).\n",
      "\n",
      "        *   **Reinforcement Learning:** The algorithm learns by trial and error in an environment to maximize a reward. Example:  Training a computer to play a game like chess. The algorithm makes moves, gets feedback (wins or loses), and adjusts its strategy to improve its chances of winning.\n",
      "\n",
      "4.  **Neural Networks and Deep Learning**\n",
      "\n",
      "    *   **Neural Networks:**  Inspired by the structure of the human brain. They consist of interconnected nodes (neurons) organized in layers.  Each connection between neurons has a weight associated with it, which represents the strength of the connection.\n",
      "    *   **Deep Learning:**  Neural networks with many layers (hence, \"deep\"). Deep learning has been revolutionary in areas like image recognition, natural language processing, and speech recognition because it can learn very complex patterns from data.\n",
      "\n",
      "    *   **How Neural Networks Work (Simplified):**\n",
      "\n",
      "        1.  **Input Layer:** Receives the raw data (e.g., pixels of an image, words in a sentence).\n",
      "        2.  **Hidden Layers:**  Process the data through multiple layers of interconnected neurons.  Each neuron applies a mathematical function to the input it receives and passes the result to the next layer. The weights on the connections between neurons are adjusted during training to improve the network's performance.\n",
      "        3.  **Output Layer:**  Produces the final result (e.g., the classification of an image, the predicted next word in a sentence).\n",
      "\n",
      "5.  **Natural Language Processing (NLP)**\n",
      "\n",
      "    *   Focuses on enabling computers to understand, interpret, and generate human language.\n",
      "    *   **Techniques used in NLP:**\n",
      "        *   **Text Analysis:**  Breaking down text into its components (words, sentences, phrases).\n",
      "        *   **Sentiment Analysis:**  Determining the emotional tone of a piece of text (positive, negative, neutral).\n",
      "        *   **Machine Translation:** Translating text from one language to another.\n",
      "        *   **Text Generation:** Creating new text, such as summaries, articles, or conversations.\n",
      "\n",
      "**Example: Image Recognition**\n",
      "\n",
      "Let's say you want to build an AI system that can recognize different breeds of dogs in images. Here's how it might work:\n",
      "\n",
      "1.  **Data:** You gather a massive dataset of images of different dog breeds, labeling each image with the breed.\n",
      "2.  **Algorithm:** You use a deep learning algorithm called a Convolutional Neural Network (CNN).  CNNs are very good at image recognition.\n",
      "3.  **Training:** You feed the data into the CNN. The network analyzes the images, learns the features that distinguish different breeds (e.g., ear shape, snout length, coat color), and adjusts the weights of its connections to improve its accuracy.\n",
      "4.  **Inference:**  Once the network is trained, you can give it a new image of a dog it hasn't seen before. The network will analyze the image and predict the dog's breed.\n",
      "\n",
      "**A More Detailed Example:  Spam Email Detection**\n",
      "\n",
      "Imagine building an AI to filter spam emails:\n",
      "\n",
      "1.  **Data Collection:**  You gather a large dataset of emails, labeling each one as either \"spam\" or \"not spam\" (also called \"ham\").  This is your training data.\n",
      "2.  **Feature Extraction:**  You need to identify features in the emails that are good indicators of spam.  Examples:\n",
      "    *   **Keywords:**  Words like \"Viagra,\" \"Lottery,\" \"Urgent,\" \"Free.\"\n",
      "    *   **Sender's Address:**  Whether the sender is on a blacklist of known spammers.\n",
      "    *   **Email Structure:**  Use of excessive exclamation marks, ALL CAPS, or unusual formatting.\n",
      "    *   **Presence of Attachments:**  Emails with certain types of attachments might be more likely to be spam.\n",
      "3.  **Model Selection:**  You choose a machine learning algorithm. A good choice here could be:\n",
      "    *   **Naive Bayes:** A simple but effective algorithm that calculates the probability of an email being spam based on the presence of certain features.\n",
      "    *   **Support Vector Machine (SVM):**  A more sophisticated algorithm that can find complex patterns in the data.\n",
      "    *   **Logistic Regression:**  Predicts the probability that an email is spam or not.\n",
      "4.  **Training:**  You feed your labeled email data and the extracted features to the chosen algorithm. The algorithm learns the relationship between the features and whether an email is spam or not.  The training process involves adjusting internal parameters within the model to minimize the error in predicting spam.\n",
      "5.  **Testing/Evaluation:** You hold back a portion of your data (the \"test set\") that the algorithm didn't see during training.  You use this test set to evaluate how well the algorithm performs. You measure metrics like:\n",
      "    *   **Accuracy:**  The percentage of emails correctly classified as spam or not spam.\n",
      "    *   **Precision:**  Out of all the emails the algorithm classified as spam, how many were actually spam? (Avoids false positives).\n",
      "    *   **Recall:**  Out of all the spam emails, how many did the algorithm correctly identify? (Avoids false negatives).\n",
      "6.  **Deployment:** Once you're satisfied with the algorithm's performance, you deploy it to your email server. The algorithm analyzes incoming emails and flags those that are likely to be spam, moving them to the spam folder.\n",
      "7.  **Continuous Improvement:**  AI systems are rarely \"done.\" You should continuously monitor the algorithm's performance and retrain it with new data to adapt to changing spam tactics.\n",
      "\n",
      "**Important Considerations:**\n",
      "\n",
      "*   **Bias:** AI systems can inherit biases from the data they are trained on.  If the training data reflects societal biases, the AI system may perpetuate those biases.\n",
      "*   **Explainability:** Some AI models (especially deep learning models) are like \"black boxes.\"  It's hard to understand why they make the decisions they do. This can be a problem in situations where transparency and accountability are important.\n",
      "*   **Ethics:**  AI raises important ethical questions about privacy, security, job displacement, and the potential for misuse.\n",
      "\n",
      "**In Conclusion**\n",
      "\n",
      "AI is a complex and rapidly evolving field.  While the underlying mathematics and algorithms can be quite intricate, the basic idea is to create machines that can learn, reason, and solve problems in a way that mimics human intelligence.  Machine learning, particularly deep learning, is driving much of the progress we're seeing in AI today. As AI becomes more pervasive, it's crucial to understand its capabilities, limitations, and potential impacts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
