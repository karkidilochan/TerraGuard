{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dilochan/Documents/projects/terraguard/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "from api_keys import GEMINI_API_KEY\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset containing prompts and sample Terraform code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"autoiac-project/iac-eval\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Resource', 'Prompt', 'Rego intent', 'Difficulty', 'Reference output',\n",
      "       'Intent'],\n",
      "      dtype='object')\n",
      "(458, 6)\n"
     ]
    }
   ],
   "source": [
    "df = dataset.to_pandas()\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      terraform {\\n  required_providers {\\n    aws =...\n",
       "1      provider \"aws\" {\\n    region = \"us-east-1\"\\n}\\...\n",
       "2      provider \"aws\" {\\n  region = \"us-east-1\"\\n}\\n\\...\n",
       "3      terraform {\\n  required_providers {\\n    aws =...\n",
       "4      terraform {\\n  required_providers {\\n    aws =...\n",
       "                             ...                        \n",
       "453    terraform {\\n  required_providers {\\n    aws =...\n",
       "454    terraform {\\n  required_providers {\\n    aws =...\n",
       "455    provider \"aws\" {\\n  region = \"us-west-1\"\\n}\\n\\...\n",
       "456    terraform {\\n  required_providers {\\n    aws =...\n",
       "457    terraform {\\n  required_providers {\\n    aws =...\n",
       "Name: Reference output, Length: 458, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Reference output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(\"templates/system_prompt.txt\", \"r\") as f:\n",
    "    system_prompt = f.read()\n",
    "\n",
    "with open(\"templates/cot.txt\", \"r\") as f:\n",
    "    cot_prompt = f.read()\n",
    "\n",
    "with open(\"templates/few-shot.txt\", \"r\") as f:\n",
    "    few_shot_prompt = f.read()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are TerraGuard, an AI agent that builds Cloud Infrastructure written in Terraform HCL. Generate a single Terraform HCL program in response to each of my Instructions. Make sure the configuration is deployable. Create IAM roles as needed. If variables are used, make sure default values are supplied. Be sure to include a valid provider configuration within a valid region. Make sure there are no undeclared resources (e.g., as references) or variables, that is, all resources and variables needed in the configuration should be fully specified. '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few-Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are a few examples:\\n\\nExample prompt 1: Create an AWS RDS instance with randomly generated id and password\\nExample output 1: \\n```hcl\\nresource \"random_id\" \"suffix\" {\\n  byte_length = 4\\n}\\n\\nresource \"random_password\" \"db\" {\\n  length  = 16\\n  special = false\\n}\\n\\nresource \"aws_db_instance\" \"test\" {\\n  identifier          = \"metricbeat-test-${random_id.suffix.hex}\"\\n  allocated_storage   = 20 // Gigabytes\\n  engine              = \"mysql\"\\n  instance_class      = \"db.t2.micro\"\\n  db_name                = \"metricbeattest\"\\n  username            = \"foo\"\\n  password            = random_password.db.result\\n  skip_final_snapshot = true // Required for cleanup\\n}\\n```\\n\\nExample prompt 2: Create an 20GB MySQL instance on aws with randomly generated id and password\\nExample output 2: \\n```hcl\\nresource \"random_id\" \"suffix\" {\\n  byte_length = 4\\n}\\n\\nresource \"random_password\" \"db\" {\\n  length  = 16\\n  special = false\\n}\\n\\nresource \"aws_db_instance\" \"test\" {\\n  identifier          = \"metricbeat-test-${random_id.suffix.hex}\"\\n  allocated_storage   = 20 // Gigabytes\\n  engine              = \"mysql\"\\n  instance_class      = \"db.t2.micro\"\\n  db_name                = \"metricbeattest\"\\n  username            = \"foo\"\\n  password            = random_password.db.result\\n  skip_final_snapshot = true // Required for cleanup\\n}\\n```\\n\\nExample prompt 3: create a AWS EFS, and create a replica of an this created EFS file system using regional storage in us-west-3\\nExample output 3: \\n```hcl\\nresource \"aws_efs_file_system\" \"example\" {}\\n\\nresource \"aws_efs_replication_configuration\" \"example\" {\\n  source_file_system_id = aws_efs_file_system.example.id\\n\\n  destination {\\n    availability_zone_name = \"us-west-2b\"\\n    kms_key_id             = \"1234abcd-12ab-34cd-56ef-1234567890ab\"\\n  }\\n}\\n```\\n\\nHere is the actual prompt to answer:'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain of thought Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are a few examples:\\n\\nExample prompt 1: Create an AWS RDS instance (with an instance class of db.t2.micro, and don\\'t create a final snapshot before eventual deletion) with randomly generated id and password\\nExample output 1: Let\\'s think step by step. First, let\\'s reason about the resources needed: this would be an AWS RDS instance (aws_db_instance), and resources to generate a random id and password. Second, we fill in the attributes of each resource, starting with those explicitly and implicitly mentioned in the prompt, and followed by others: for example, for the aws_db_instance, we need to set the \"instance_class\" attribute to \"db.t2.micro\", and the \"skip_final_snapshot\" attribute to true. Finally, we connect the resources together, as needed: here \"identifier\" should be connected to the \"random_id\" resource, and \"password\" should be connected to the \"random_password\" resource\\n```hcl\\nresource \"random_id\" \"suffix\" {\\n  byte_length = 4\\n}\\n\\nresource \"random_password\" \"db\" {\\n  length  = 16\\n  special = false\\n}\\n\\nresource \"aws_db_instance\" \"test\" {\\n  identifier          = \"metricbeat-test-${random_id.suffix.hex}\"\\n  allocated_storage   = 20 // Gigabytes\\n  engine              = \"mysql\"\\n  instance_class      = \"db.t2.micro\"\\n  db_name                = \"metricbeattest\"\\n  username            = \"foo\"\\n  password            = random_password.db.result\\n  skip_final_snapshot = true // Required for cleanup\\n}\\n```\\n\\nExample prompt 2: Create an 20GB MySQL instance on aws with randomly generated id and password\\nExample output 2: Let\\'s think step by step. First, let\\'s reason about the resources needed: this would be an AWS RDS instance (aws_db_instance), and resources to generate a random id and password. Second, we fill in the attributes of each resource, starting with those explicitly and implicitly mentioned in the prompt, and followed by others: for example, for the aws_db_instance, we need to set the \"engine\" attribute to \"mysql\". Finally, we connect the resources together, as needed: here \"identifier\" should be connected to the \"random_id\" resource, and \"password\" should be connected to the \"random_password\" resource\\n```hcl\\nresource \"random_id\" \"suffix\" {\\n  byte_length = 4\\n}\\n\\nresource \"random_password\" \"db\" {\\n  length  = 16\\n  special = false\\n}\\n\\nresource \"aws_db_instance\" \"test\" {\\n  identifier          = \"metricbeat-test-${random_id.suffix.hex}\"\\n  allocated_storage   = 20 // Gigabytes\\n  engine              = \"mysql\"\\n  instance_class      = \"db.t2.micro\"\\n  db_name                = \"metricbeattest\"\\n  username            = \"foo\"\\n  password            = random_password.db.result\\n  skip_final_snapshot = true // Required for cleanup\\n}\\n```\\n\\nExample prompt 3: create a AWS EFS, and create a replica of an this created EFS file system using regional storage in us-west-2\\nExample output 3: Let\\'s think step by step. First, let\\'s reason about the resources needed: this would be an AWS EFS replication resource (aws_efs_replication_configuration), and  the AWS EFS resource itself. Second, we fill in the attributes of each resource, starting with those explicitly and implicitly mentioned in the prompt, and followed by others: for example, for the aws_efs_replication_configuration, we need to set the \"availability_zone_name\" attribute to an availability zone that will be within the region specificed in the prompt, such as \"us-west-2b\". Finally, we connect the resources together, as needed: here \"source_file_system_id\" should be connected to the \"aws_efs_file_system\" resource\\n```hcl\\nresource \"aws_efs_file_system\" \"example\" {}\\n\\nresource \"aws_efs_replication_configuration\" \"example\" {\\n  source_file_system_id = aws_efs_file_system.example.id\\n\\n  destination {\\n    availability_zone_name = \"us-west-2b\"\\n    kms_key_id             = \"1234abcd-12ab-34cd-56ef-1234567890ab\"\\n  }\\n}\\n```\\n\\nHere is the actual prompt to answer. Let\\'s think step by step:'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Create a VPC with private subnets. Create 2 of the newest AWS Linux 2 EC2 instances in the private subnet mounting an EFS file system for shared storage.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = df[df['Difficulty'] == 6]\n",
    "random_prompt = temp_df['Prompt'].sample().iloc[0]\n",
    "random_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated Terraform code with different prompting strategies for a same prompt, at different difficulty levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for difficulty in range(1, 7):\n",
    "    temp_df = df[df['Difficulty'] == difficulty]\n",
    "    prompt = temp_df['Prompt'].sample().iloc[0]\n",
    "\n",
    "\n",
    "    response = gemini_client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\", \n",
    "            config = types.GenerateContentConfig(\n",
    "                temperature=0.1,\n",
    "                system_instruction=system_prompt\n",
    "            ),\n",
    "            contents= prompt\n",
    "\n",
    "        )\n",
    "    with open(f\"prompt_results/zero_shot_{difficulty}.txt\", \"w\") as file:\n",
    "        file.write(response.text)\n",
    "\n",
    "    time.sleep(60)\n",
    "\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\", \n",
    "        config = types.GenerateContentConfig(\n",
    "            temperature=0.1,\n",
    "            system_instruction=system_prompt\n",
    "        ),\n",
    "        contents=few_shot_prompt + prompt\n",
    "\n",
    "    )\n",
    "    with open(f\"prompt_results/few_shot_{difficulty}.txt\", \"w\") as file:\n",
    "        file.write(response.text)\n",
    "\n",
    "    time.sleep(60)\n",
    "    response = gemini_client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\", \n",
    "            config = types.GenerateContentConfig(\n",
    "                temperature=0.1,\n",
    "                system_instruction=system_prompt\n",
    "            ),\n",
    "            contents=cot_prompt + prompt\n",
    "        )\n",
    "    with open(f\"prompt_results/cot_{difficulty}.txt\", \"w\") as file:\n",
    "        file.write(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terraform file 'output.tf' has been created successfully!\n",
      "Terraform file 'output.tf' has been created successfully!\n",
      "Terraform file 'output.tf' has been created successfully!\n",
      "Terraform file 'output.tf' has been created successfully!\n",
      "Terraform file 'output.tf' has been created successfully!\n",
      "Terraform file 'output.tf' has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Read the input text file\n",
    "for i in range(1, 7):\n",
    "    with open(f\"prompt_results/cot_{i}.txt\", \"r\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Extract Terraform code block using regex\n",
    "    match = re.search(r\"```hcl\\n(.*?)\\n```\", content, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        terraform_code = match.group(1)  # Extracted Terraform config\n",
    "\n",
    "        # Write to a Terraform file\n",
    "        with open(f\"generated_tf/cot_{i}.tf\", \"w\") as tf_file:\n",
    "            tf_file.write(terraform_code)\n",
    "\n",
    "        print(\"Terraform file 'output.tf' has been created successfully!\")\n",
    "    else:\n",
    "        print(\"No Terraform code block found in the input file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terraform file 'output.tf' has been created successfully!\n",
      "Terraform file 'output.tf' has been created successfully!\n",
      "Terraform file 'output.tf' has been created successfully!\n",
      "Terraform file 'output.tf' has been created successfully!\n",
      "Terraform file 'output.tf' has been created successfully!\n",
      "Terraform file 'output.tf' has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Read the input text file\n",
    "for i in range(1, 7):\n",
    "    with open(f\"prompt_results/few_shot_{i}.txt\", \"r\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Extract Terraform code block using regex\n",
    "    match = re.search(r\"```hcl\\n(.*?)\\n```\", content, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        terraform_code = match.group(1)  # Extracted Terraform config\n",
    "\n",
    "        # Write to a Terraform file\n",
    "        with open(f\"generated_tf/few_shot_{i}.tf\", \"w\") as tf_file:\n",
    "            tf_file.write(terraform_code)\n",
    "\n",
    "        print(\"Terraform file 'output.tf' has been created successfully!\")\n",
    "    else:\n",
    "        print(\"No Terraform code block found in the input file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terraform file 'output.tf' has been created successfully!\n",
      "Terraform file 'output.tf' has been created successfully!\n",
      "Terraform file 'output.tf' has been created successfully!\n",
      "Terraform file 'output.tf' has been created successfully!\n",
      "Terraform file 'output.tf' has been created successfully!\n",
      "Terraform file 'output.tf' has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Read the input text file\n",
    "for i in range(1, 7):\n",
    "    with open(f\"prompt_results/zero_shot_{i}.txt\", \"r\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Extract Terraform code block using regex\n",
    "    match = re.search(r\"```terraform\\n(.*?)\\n```\", content, re.DOTALL)\n",
    "    file_name = f\"generated_tf/zero_shot_{i}.tf\"\n",
    "\n",
    "    if match:\n",
    "        terraform_code = match.group(1)  # Extracted Terraform config\n",
    "\n",
    "        # Write to a Terraform file\n",
    "        with open(file_name, \"w\") as tf_file:\n",
    "            tf_file.write(terraform_code)\n",
    "\n",
    "        print(\"Terraform file 'output.tf' has been created successfully!\")\n",
    "    else:\n",
    "        print(\"No Terraform code block found in the input file.\" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
